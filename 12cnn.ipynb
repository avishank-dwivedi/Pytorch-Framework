{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXguKBQYtZFcffAY5WxQOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avishank-dwivedi/Pytorch-Framework/blob/main/12cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu_NsSDUZ4rp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "jWOr_MDWk5rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"using device: {device}\")"
      ],
      "metadata": {
        "id": "yOLqzH41BZZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the file (just adjust the path)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/pytorch/fashion-mnist_train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_UFMZ0w7k8wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ARWjmib9k-_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a 4*4 grid of images\n",
        "fig, axes = plt.subplots(4 , 4 , figsize=(10 , 10))\n",
        "fig.suptitle(\"first 16 /images\" , fontsize=16)\n",
        "\n",
        "#plot the first 16 image from the dataset\n",
        "for i , ax in enumerate(axes.flat):\n",
        "    img = df.iloc[i , 1:].values.reshape(28 , 28) #Reshape to 28*28\n",
        "    ax.imshow(img)# display in grayscale\n",
        "    ax.axis('off') # Remove axis for a clear look\n",
        "    ax.set_title(f\"Label: {df.iloc[i , 0]}\") #show the label\n",
        "\n",
        "plt.tight_layout(rect = [0,0,1,0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uqhRPRm_lB1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "df = df.dropna()\n",
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Ef0kfdiElKAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformations\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "custom_transform = transforms.Compose([\n",
        "transforms.Resize((256)),\n",
        "transforms.CenterCrop(224),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "PEt7siV7Crpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self , features , labels , transforms):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self  , index):\n",
        "    #resize to (28 , 28)\n",
        "    image = self.features[index].reshape(28,28) # Corrected from self.feature\n",
        "\n",
        "    #change dataset to np.unit8\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    #change black&white to colr - > (H,w , c)-> (c, h , w)\n",
        "    image = np.stack([image]*3, axis=-1) # Added axis=0 for correct stacking\n",
        "\n",
        "    #convert array to PIL image\n",
        "    image = Image.fromarray(image) # This line is not needed as ToTensor will handle the conversion from numpy array\n",
        "\n",
        "    #apply transforms\n",
        "    image = self.transforms(image) # Apply transforms to a torch tensor\n",
        "\n",
        "    #return\n",
        "    return image , torch.tensor(self.labels[index] , dtype=torch.long)"
      ],
      "metadata": {
        "id": "-w6zcDmHELFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create train dataset object\n",
        "train_dataset = CustomDataset(X_train , y_train , transforms=custom_transform)"
      ],
      "metadata": {
        "id": "yOYkc8FclyH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "6Jpeu8Y7lypn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create test_dataset  object\n",
        "test_dataset = CustomDataset(X_test , y_test , transforms=custom_transform)"
      ],
      "metadata": {
        "id": "onu-MuJ_l0by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "id": "ati_e_BAl2yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create train and test loader\n",
        "train_loader = DataLoader(train_dataset , batch_size=32 , shuffle=True)\n",
        "test_loader = DataLoader(test_dataset , batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "QH_WqXuql460"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#featch the pretrain model\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "id": "wuwGdGEPmNTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16\n"
      ],
      "metadata": {
        "id": "pooJYHFyI9Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parm in vgg16.features.parameters():\n",
        "  parm.requires_grad = False"
      ],
      "metadata": {
        "id": "iY4PLUHiLaSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(25088 , 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024 , 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512 , 10)\n",
        ")\n"
      ],
      "metadata": {
        "id": "uEyXq6CbMGuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = vgg16.to(device)"
      ],
      "metadata": {
        "id": "7xqzfqZjM3G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "7tUgAYptYnqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.Adam(vgg16.classifier.parameters() , lr=learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "kV2Exzr_ZSMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  total_epoch_loss = 0\n",
        "  for batch_features , batch_labels in train_loader:\n",
        "\n",
        "    #move data on gpu\n",
        "\n",
        "    batch_features , batch_labels = batch_features.to(device),batch_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    output = vgg16(batch_features)\n",
        "\n",
        "    #calculate loss\n",
        "    loss = criterion(output , batch_labels)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    #update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs} , Loss : {avg_loss}\")"
      ],
      "metadata": {
        "id": "m7O4r4qSZz2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8b445d-f666-4fe6-a064-0cde9c736fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 , Loss : 0.36688610225170853\n",
            "Epoch 2/10 , Loss : 0.21619102658952277\n",
            "Epoch 3/10 , Loss : 0.16829753732153524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set model to eval mode\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "3x8nDtqrakT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation code\n",
        "\n",
        "total =0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features , batch_labels in test_loader:\n",
        "\n",
        "     #move data on gpu\n",
        "\n",
        "    batch_features , batch_labels = batch_features.to(device),batch_labels.to(device)\n",
        "\n",
        "\n",
        "    output = vgg16(batch_features)\n",
        "\n",
        "    _,predicted = torch.max(output.data , 1)\n",
        "\n",
        "    total += batch_labels.shape[0]\n",
        "    correct += (predicted == batch_labels).sum().item()\n",
        "print(correct/total)"
      ],
      "metadata": {
        "id": "6U2d15MValLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}